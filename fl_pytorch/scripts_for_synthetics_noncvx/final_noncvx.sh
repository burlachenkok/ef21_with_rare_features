#!/usr/bin/env bash

source change_direcotry.sh

# EF21 enhanced
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "1000" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "51q_02_job_id_1681919037_{now}" --algorithm "ef21" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,ef21_scaled:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.05,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "topk:1" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "X2_job_id_1681919037_sel_0_99.bin" 1>X2.stdout 2>X2.stderr &
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "1000" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "11q_06_job_id_1681919037_{now}" --algorithm "ef21" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,ef21_scaled:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.5,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "topk:1" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "X6_job_id_1681919037_sel_0_99.bin" 1>X6.stdout 2>X6.stderr &
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "1000" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "11q_ajob_id_168191903_{now}" --algorithm "ef21" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,ef21_scaled:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.9,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "topk:1" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "X8_job_id_1681919037_sel_0_99.bin" 1>X8.stdout 2>X8.stderr &

# EF21 standart
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "1000" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "21q_01_job_id_1681919037_{now}" --algorithm "ef21" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.05,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "topk:1" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "X1_job_id_1681919037_sel_0_99.bin" 1>X1.stdout 2>X1.stderr &
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "1000" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "11q_05_job_id_1681919037_{now}" --algorithm "ef21" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.5,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "topk:1" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "X5_job_id_1681919037_sel_0_99.bin" 1>X5.stdout 2>X5.stderr &
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "1000" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "11q__07_job_id_1681919037_{now}" --algorithm "ef21" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.9,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "topk:1" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "X7_job_id_1681919037_sel_0_99.bin" 1>X7.stdout 2>X7.stderr &

# GD
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "0" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "20" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "21q_jjob_id_1681919037_{now}" --algorithm "fedavg" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.05,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "XD_1_job_id_1681919037_sel_0_99.bin" 1>X_GD_1.stdout 2>X_GD_1.stderr &
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "0" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "20" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "112q_ljob_id_1681919037_{now}" --algorithm "fedavg" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.5,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "X_GD_5_job_id_1681919037_sel_0_99.bin" 1>X_GD_5.stdout 2>X_GD_5.stderr &
nohup python run.py --rounds "10000" --client-sampling-type "all" --global-lr "0" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "12" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:20,samples_per_client:12,clients:100,variables:500" --loss "mse" --model "linear" --metric "loss" --global-regulizer "noncvx_robust_linear_regression" --global-regulizer-alpha "3.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "desktop-n968j9a" --eval-every "20" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --run-id "118q_mjob_id_1681919037_{now}" --algorithm "fedavg" --algorithm-options "internal_sgd:full-gradient,n_multiplier:1,k_separable:3,stepsize_multiplier:1,th_stepsize_cvx:1,b_perurbation:2.0,remove_probability:0.0,reduce_samples_by:1.0,c_div_n:0.9,l_plus_min_selector:0.1" --logfile "../logs/16_log_1681919037.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "X_GD_7_job_id_1681919037_sel_0_99.bin" 1>X_GD_7.stdout 2>X_GD_7.stderr &
